{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickwharff/CS167_Notes/blob/main/Day12Notes_RNNs4NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTDTrsuy3BVo"
      },
      "source": [
        "# Recurrent Neural Networks for Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnQc446427-T",
        "outputId": "040d786e-2dc9-4037-a7f9-86fd3c4aef64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#imports and things\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    !pip install -q -U transformers\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4TqE64f3R3d"
      },
      "source": [
        "## Char-RNN\n",
        "\n",
        "### Loading and Preparing the Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXP2YlHO3fMZ",
        "outputId": "e73bb3f4-2dc0-401b-879c-73a66fad6759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7oFxQlG3lhD",
        "outputId": "6ae0a060-563a-4042-9b6b-d6bc3d019e46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(shakespeare_text[:148])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_QwH8Ev3oOv",
        "outputId": "ca7171a4-3576-41d3-e7ac-dc045fa4b38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# The vocabulary of our character-level language model looks like this:\n",
        "\"\".join(sorted(set(shakespeare_text.lower())))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWRdLdg3v-G"
      },
      "source": [
        "# Use Tokenizer to tokenize the Shakespeare text\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAkOhr8236Rf",
        "outputId": "9bb6a47b-8a9a-428b-825f-1b0a6920fc41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Embed the word 'First' as tokens:\n",
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLm-SCCM3-uz",
        "outputId": "73c15245-1499-4aff-c6e4-9369f97fc48f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Revert the sequence of tokens back to the word:\n",
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqWg3zk94LAY",
        "outputId": "414d07ea-f63d-44ee-dd60-825342a707cd"
      },
      "source": [
        "# Dataset prep\n",
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters\n",
        "\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "\n",
        "dataset = dataset.prefetch(1)\n",
        "\n",
        "\n",
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 39) (32, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneQNZKY4uWZ"
      },
      "source": [
        "## Creating and Training the Model\n",
        "If you are not connected to a GPU, this code will likely take hours to run.\n",
        "\n",
        "If you are connected to a GPU, you should be able to run this at about 5-10 minute per epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvQ1H6TT4O1E",
        "outputId": "8b9e0ca2-7a12-49c1-e5e1-fbcd259d986e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(64, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(64, return_sequences=True,\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
        "                    epochs=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "31370/31370 [==============================] - 448s 14ms/step - loss: 1.8363\n",
            "Epoch 2/2\n",
            "31370/31370 [==============================] - 429s 14ms/step - loss: 1.7544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1SJD1JhxfBmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "6eb12c63-0099-4c25-91c0-cedef5c9fcb2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-1R3kOy5euX"
      },
      "source": [
        "## Using the Model to Generate Text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BHV5ak4SRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80a457ea-6deb-45e3-cb0c-56455e10f837"
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)\n",
        "\n",
        "# Let's pass in 'How are yo' and see what it predicts the next letter should be:\n",
        "X_new = preprocess([\"How are yo\"])\n",
        "\n",
        "#this line takes a look at the softmax output and returns the max\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZMtUeBh6JDN"
      },
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfPS9_936K-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "992a4ad2-6f3d-45b7-85ea-a7a3f66197e1"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "next_char(\"How are yo\", temperature=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vDjXtnV6Pgr"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGQLDBQXH6M_"
      },
      "source": [
        "**Temperature** controls the randomness of the outputs, a larger temperature means a less confident, but more random output (more errors, less logic), while a lower temperature is a more confident but less random output. Take a look below to see how temperature influences the predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpjzl6LJ6Umm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0314b73-6655-4b27-96f7-c04844e47f32"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"t\", temperature=0.3))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the state and though a strange and belly her to the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XswPMxn_6Xgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e383645e-c58a-4fde-f28b-c6dddc6f6580"
      },
      "source": [
        "print(complete_text(\"t\", temperature=1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to compa\n",
            "do you delpoble construct your hondures.\n",
            "y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heAuNZgb6Zgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0d22d9-3e60-40e2-f7a0-29f3c13b73dd"
      },
      "source": [
        "print(complete_text(\"t\", temperature=2))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpeniome\n",
            "that? it?\n",
            "\n",
            "jude:\n",
            "lebevil! deniburs:\n",
            "-y! er\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phmVSDnsIlSK"
      },
      "source": [
        "# In Class Exercise: \n",
        "\n",
        "With your group, answer the following:\n",
        "- Play around with the `complete_text` function, try different character lengths. What is the best output you got? \n",
        "\n",
        "- Do you think we trained the model long enough? Do you expect the predictions to be better if we made the model larger or trained the model longer? Why or why not?\n",
        "  - i do think the model would be better if it was trained for longer, we only did 2 epochs, so we could get better results with more epochs\n",
        "\n",
        "- Does anything surprise you about the predictions? Why or why not?\n",
        "  - alot of the words are almost english, instead of real words\n",
        "\n",
        "- How would you go about improving the model? What hyperparameters would you consider changing?\n",
        "  - temperature\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pywar4mmHqkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37959901-76eb-4017-c0ce-1a7a5707445c"
      },
      "source": [
        "print(complete_text(\"the\", temperature=0.5, n_chars=1000))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the love to the roys!\n",
            "what shall not feals in the tine to their farst and patter with leave to come\n",
            "the worse to the country as men see the rish.\n",
            "\n",
            "first citizen:\n",
            "where make you wood what in love.\n",
            "\n",
            "first citizen:\n",
            "gentleman we live do you say you than accors and lentle of the belly worst be belly with your elee.\n",
            "\n",
            "menenius:\n",
            "sir, i will make me, tranio,\n",
            "the string on their trumio, i say he please the sack me with these are to they sholl the receive\n",
            "in purpering be free the fit a good worth to head to my time to the cortune.\n",
            "\n",
            "first citizen:\n",
            "the tore my father that as the begs this charce\n",
            "and i must in her and since be the sins to the condress to\n",
            "patition and strong the their was make not be are and the nortens of the country\n",
            "that me to the begs to the rome and me to fare his trucks\n",
            "what all the rate make so who enders who have the groan on all comes\n",
            "the change you have heart word,\n",
            "that i know you may not though me for the words, the all instruction your lives\n",
            "to the device to the dear and what\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6sXR1n_Id2g"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}